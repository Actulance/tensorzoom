# TensorZoom-TF

This is a Tensorflow project of super-resolution that implemented the paper [Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network](https://arxiv.org/abs/1609.04802). The TensorZoom network can scale up an image by 4 time its width and height and it has significantly better result comparing with bilinear scale up of an image. The training process is based on adversarial training that use a discriminative network and a generative network alternatively in order to achieve a better visual result.

##Modifications
- This implementation is mainly focus on mobile usage. Therefore only 6 batch normalistion layers is used to decrease the loading.
- In general, mobile device can only afford to calculate a at most 120x120 image. So a large image is sliced into smaller tiles to do the scaling. Then the tiles are stitched together to form a large image. In order to improve the quality of the stitched result, we added logic to slice the input image into 16 smaller images and concat them together to form a batch for training. This method can greatly improve the quality when multiple scaled images are stitched together.
- A additional deblur training is added. The input image is blurred using ```tf.nn.depthwise_conv2d```. The quality is much better for the image taken from mobile camera but worse than normal for small images or thumbnails.

##Samples
Here are some sample result generated by this algorithm.(click to download the full size to see the result)
<table>
  <tr>
    <td><img src="https://github.com/machrisaa/tensorzoom/blob/master/analysis/cat_h.jpg?raw=true"/></td>
    <td><img src="https://github.com/machrisaa/tensorzoom/blob/master/analysis/cat_h_tz6-s-stitch-gen.jpg?raw=true"/></td>
  </tr>
</table>
<table>
  <tr>
    <td><img src="https://github.com/machrisaa/tensorzoom/blob/master/analysis/london2.jpg?raw=true"/></td>
    <td><img src="https://github.com/machrisaa/tensorzoom/blob/master/analysis/london2_tz6-s-stitch-sblur-notv-gen.jpg?raw=true"/></td>
  </tr>
</table>

##How to use
To test scaling up an image is simple and do not require extra files and project. 
> An example is provided in ```net_analysis.py```.


To train the network need to change the setup in ```trainer.py```:
```
# https://github.com/machrisaa/tensorflow-vgg
VGG_NPY_PATH = '../tensoflow_vgg/vgg19.npy'

# http://msvocds.blob.core.windows.net/coco2014/train2014.zip
COCO2014_PATH = '../../datasets/coco2014/train2014'
```
The training need to use a the result of the ```conv2_2``` layer from a pre-trained VGG19 network - [Tensorflow-VGG](https://github.com/machrisaa/tensorflow-vgg). The dataset we are using is the Microsoft Coco2014 data set - [2014 Training images [80K/13GB] data set](http://mscoco.org/dataset/#download).
Download and update the path in ```trainer.py``` before start running this file.


